{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our training and test sets\n",
    "train_dataset = FashionMNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "test_dataset = FashionMNIST(root=\".\", train=False, download=True, transform=transform)\n",
    "# creating our dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",  \"Sandal\",  \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textsf{Convolution:} \\left\\lfloor \\frac{D_{i}-D_{f}+2p}{s} \\right\\rfloor + 1 \\quad \\quad \\quad \\textsf{Pooling:} \\left\\lfloor \\frac{D_{i}}{D_{f}} \\right\\rfloor$$\n",
    "\n",
    "$$D_{i} = \\textsf{Dimension of input}; \\quad D_{f} = \\textsf{Dimension of filter (kernel)}; \\quad p = \\textsf{Padding}; \\quad s = \\textsf{Stride}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://datascience.stackexchange.com/a/64281\n",
    "# https://stats.stackexchange.com/a/292064\n",
    "# https://arxiv.org/pdf/1603.07285v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image properties:\n",
    "# (Width, Height, Channel) = (28, 28, 1)\n",
    "# Channel: (1 for grayscale) or (3 for RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dimension():\n",
    "    def __init__(self, size, RGB=False):\n",
    "        self.__size:int = size\n",
    "        self.__in_channels:int = 3 if RGB else 1\n",
    "        self.printDimension('Inital tensor size')\n",
    "\n",
    "    def printDimension(self, text=\"Tensor size:\"):\n",
    "        print(f\"{text}: {self.__size}x{self.__size}x{self.__in_channels}\")\n",
    "   \n",
    "    def Convolution(self, out_channels:int, kernel_size:int, stride=1, padding=0):\n",
    "        self.__in_channels = out_channels\n",
    "        self.__size = ((self.__size - kernel_size + 2*padding) // stride) + 1\n",
    "        self.printDimension('After convolution')\n",
    "        return self\n",
    "   \n",
    "    def Pooling(self, kernel_size:int):\n",
    "        self.__size = self.__size // kernel_size\n",
    "        self.printDimension('After pooling')\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital tensor size: 28x28x1\n",
      "After convolution: 24x24x32\n",
      "After pooling: 12x12x32\n",
      "After convolution: 8x8x64\n",
      "After pooling: 4x4x64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Dimension at 0x28414efe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 28 # 28x28\n",
    "Prepocessing = Dimension(size=image_size, RGB=False)\n",
    "Prepocessing.Convolution(32, kernel_size=5).Pooling(2).Convolution(64, kernel_size=5).Pooling(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # call the parent constructor\n",
    "        super(ConvNet, self).__init__()\n",
    "                \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.flatten = nn.Flatten() # input tensor have to be flattened \n",
    "        self.fc1 = nn.Linear(in_features=4*4*64, out_features=256)\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.drop2 = nn.Dropout(p=0.3)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # Pass through sequence-1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        # Pass through sequence-2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        # Pass through classifier\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:11<00:00, 80.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.6798, Test Accuracy: 99.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:11<00:00, 83.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.3694, Test Accuracy: 99.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:11<00:00, 83.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.3142, Test Accuracy: 99.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:11<00:00, 83.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.2833, Test Accuracy: 99.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:11<00:00, 84.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.2577, Test Accuracy: 99.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 85.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.2378, Test Accuracy: 99.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 85.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.2226, Test Accuracy: 99.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:11<00:00, 84.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.2064, Test Accuracy: 99.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 85.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.1942, Test Accuracy: 99.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:11<00:00, 82.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.1804, Test Accuracy: 99.73%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training the model ===============\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Compute average training loss\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Testing the model ===============\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    # Compute average test loss\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # Compute test accuracy\n",
    "    test_accuracy = 100.0 - test_loss\n",
    "\n",
    "    # Print training and testing statistics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
